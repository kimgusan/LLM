{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab44d30b-7aee-47b7-b35e-0e0ecd0a5e21",
   "metadata": {},
   "source": [
    "# 5.5 대화형 챗봇 만들기\n",
    "- 라이브러리: langchain, streamlit, streamlit_chat, faiss-cpu\n",
    "- 언어모델: gpt-4\n",
    "- 벡터 데이터베이스: 파이스(FAISS)\n",
    "\n",
    ">  stream_chat: 챗봇 사용자 인터페이스를 생성하는데 사용  \n",
    "> faiss-cpu: 벡터 검색을 위한 인덱싱 및 검색 알고리즘\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e9647c-4055-4f22-8f6b-b13d41db0b47",
   "metadata": {},
   "source": [
    "## 코드 흐름\n",
    "> 질문 -> 임베딩 -> 관련문서(파이스 저장) -> 결합(합침) -> (질문 + 관련문서) -> LLM -> 답변생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78edc235-1c4f-44f8-9e96-fed479ef6463",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-20 13:33:05.017 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "from streamlit_chat import message\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.vectorstores import FAISS\n",
    "import tempfile\n",
    "from langchain.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "833bc93e-2cb1-4b72-b1b5-6d8cf3a295b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요시 api key 입력 필요\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b02db742-04a2-4129-8a31-ba5d37134ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-20 14:00:23.854 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-09-20 14:00:23.856 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-09-20 14:00:23.866 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-09-20 14:00:23.891 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /opt/anaconda3/envs/llm_project/lib/python3.8/site-packages/ipykernel_launcher.py [ARGUMENTS]\n",
      "2024-09-20 14:00:23.892 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "uploaded_file = st.sidebar.file_uploader(\"upload\", type=\"pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9646f9ad-bef0-4321-808e-3cc9d22b83ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용자에 의해 PDF 파일 업로드\n",
    "if uploaded_file:\n",
    "    with tempfile.NamedTemporaryFile(delete=False) as tmp_file:\n",
    "        tmp_file.write(uploaded_file.getvalue())\n",
    "        tmp_file_path = tmp_file.name  # tmp_file_name -> tmp_file.name 으로 수정\n",
    "        \n",
    "    loader = PyPDFLoader(tmp_file_path)\n",
    "    data = loader.load()\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    vectors = FAISS.from_documents(data, embeddings)\n",
    "\n",
    "    # ConversationalRetrievalChain으로 대화형 챗봇 구성\n",
    "    chain = ConversationalRetrievalChain.from_llm(llm=ChatOpenAI(temperature=0, model_name='gpt-4'), retriever=vectors.as_retriever())\n",
    "\n",
    "    # 문맥 유지를 위해 과거 대화 이력을 추가(append)\n",
    "    def conversational_chat(query):\n",
    "        result = chain({\n",
    "            \"question\": query,\n",
    "            \"chat_history\": st.session_state['history']\n",
    "        })\n",
    "        st.session_state['history'].append((query, result[\"answer\"]))\n",
    "        return result[\"answer\"]\n",
    "\n",
    "    # 초기 질문과 답변에 대한 처리(PDF 파일이 업로드되면 보이는 화면 처리) \n",
    "    if 'history' not in st.session_state:\n",
    "        st.session_state['history'] = []\n",
    "\n",
    "    if 'generated' not in st.session_state:\n",
    "        st.session_state['generated'] = [\"안녕하세요! \" + uploaded_file.name + \"에 관해 질문 주세요.\"]\n",
    "\n",
    "    if 'past' not in st.session_state:\n",
    "        st.session_state['past'] = [\"안녕하세요!\"]\n",
    "\n",
    "    # 챗봇 이력에 대한 컨테이너\n",
    "    response_container = st.container()\n",
    "    # 사용자가 입력한 문장에 대한 컨테이너\n",
    "    container = st.container()\n",
    "\n",
    "    with container:\n",
    "        with st.form(key='Conv_question', clear_on_submit=True):\n",
    "            user_input = st.text_input(\"Query\", placeholder=\"PDF 파일에 대해 얘기해볼까요? (:\", key='input')\n",
    "            submit_button = st.form_submit_button(label='Send')\n",
    "        # 사용자가 질문을 입력하거나, [Send] 버튼을 눌렀을 때 처리\n",
    "        if submit_button and user_input:\n",
    "            output = conversational_chat(user_input)\n",
    "            # 사용자의 질문이나 LLM에 대한 결과를 계속 추가(append)\n",
    "            st.session_state['past'].append(user_input)\n",
    "            st.session_state['generated'].append(output)\n",
    "    \n",
    "    # LLM 이 답변을 해야 하는 경우에 대한 처리\n",
    "    if st.session_state['generated']:\n",
    "        with response_container:\n",
    "            for i in range(len(st.session_state['generated'])):\n",
    "                message(st.session_state[\"past\"][i], is_user=True,\n",
    "                        key=str(i) + '_user', avatar_style=\"fun_emoji\", seed=\"Nala\")\n",
    "                message(st.session_state[\"generated\"][i], key=str(i), avatar_style=\"bottts\", seed=\"Fluffy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de653ae-70c6-4ef2-a0dc-57bfb9849159",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec20e76d-ad52-40d7-aacd-54a02f9ab6c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_project",
   "language": "python",
   "name": "llm_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
