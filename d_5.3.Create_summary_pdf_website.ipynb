{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab44d30b-7aee-47b7-b35e-0e0ecd0a5e21",
   "metadata": {},
   "source": [
    "# 5.3 RAG ê¸°ë°˜ì˜ ì±—ë´‡ ë§Œë“¤ê¸°\n",
    "- ë¼ì´ë¸ŒëŸ¬ë¦¬: langchain, openai, PyPDF2, sentence-transformers\n",
    "- ì–¸ì–´ëª¨ë¸: gpt-3.5-turbo\n",
    "- ì„ë² ë”©ëª¨ë¸: all_MiniLM-L6-v2\n",
    "- ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤: íŒŒì´ìŠ¤(FAISS)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e9647c-4055-4f22-8f6b-b13d41db0b47",
   "metadata": {},
   "source": [
    "## ì½”ë“œ íë¦„\n",
    "> ì‚¬ìš©ìê°€ PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ë©´ ê·¸ê²ƒì„ ì²­í¬ë¡œ ë¶„í• í•˜ê³  ì„ë² ë”© ì²˜ë¦¬  \n",
    "> ê·¸ë¦¬ê³  LLM í•œí…Œ í•´ë‹¹ íŒŒì¼ì„ ìš”ì•½í•´ ë‹¬ë¼ê³  ì¿¼ë¦¬ë¥¼ ë˜ì§€ëŠ” íë¦„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a51ee8ae-9758-4847-be9a-15e53519e298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyPDF2\n",
      "  Using cached pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: typing_extensions>=3.10.0.0 in /opt/anaconda3/envs/llm_project/lib/python3.8/site-packages (from PyPDF2) (4.12.2)\n",
      "Using cached pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
      "Installing collected packages: PyPDF2\n",
      "Successfully installed PyPDF2-3.0.1\n"
     ]
    }
   ],
   "source": [
    "# !pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb4c4f5c-5ed5-4b32-bf2c-613f223cc08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PyPDF2 import PdfReader\n",
    "import streamlit as st\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain import FAISS\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.callbacks import get_openai_callback\n",
    "\n",
    "# ì „ì²˜ë¦¬\n",
    "def process_text(text):\n",
    "    #CharacterTextSplitterë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ë¡œ ë¶„í• \n",
    "    text_splitter = CharacterTextSplitter(\n",
    "        separator=\"\\n\",\n",
    "        chunk_size =1000,\n",
    "        chunk_overlap=200,\n",
    "        length_function = len\n",
    "    )\n",
    "    chunks = text_splitter.split_text(text)\n",
    "\n",
    "    # ì„ë² ë”© ì²˜ë¦¬(ë²¡í„° ë³€í™˜), ì„ë² ë”©ì€ HuggingFacsEmbeddings ëª¨ë¸ ì‚¬ìš©\n",
    "    embeddings = HuggingFaceEmbeddings(model_name = \"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    documents = FAISS.from_texts(chunks, embeddings)\n",
    "    return documents\n",
    "\n",
    "\n",
    "def main(): #streamlitì„ ì´ìš©í•œ ì›¹ì‚¬ì´íŠ¸ ìƒì„±\n",
    "    st.title(\"ğŸ“œPDF ìš”ì•½í•˜ê¸°\")\n",
    "    st.divider()\n",
    "    try:\n",
    "        # os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "    except ValueError as e:\n",
    "        st.error(str(e))\n",
    "        return\n",
    "\n",
    "    pdf = st.file_uploader(\"PDFíŒŒì¼ì„ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”\", type='pdf')\n",
    "\n",
    "    if pdf is not None:\n",
    "        pdf_reader = PdfReader(pdf)\n",
    "        text = \"\" # í…ìŠ¤íŠ¸ ë³€ìˆ˜ì— PDF ë‚´ìš©ì„ ì €ì¥\n",
    "        for page in pdf_reader.pages:\n",
    "            text += page.extract_text()\n",
    "\n",
    "        documents = process_text(text)\n",
    "        query = \"ì—…ë¡œë“œëœ PDF íŒŒì¼ì„ ë‚´ìš©ì„ ì•½ 3~5ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”.\" # LLMì— PDFíŒŒì¼ ìš”ì•½ ìš”ì²­\n",
    "\n",
    "        if query:\n",
    "            docs = documents.similarity_search(query)\n",
    "            llm = ChatOpenAI(model = 'gpt-3.5-turbo', temperature = 0.1)\n",
    "            chain = load_qa_chain(llm, chain_type = \"stuff\")\n",
    "    \n",
    "            with get_openai_callback() as cost:\n",
    "                response = chain.run(input_documents=docs, question=query)\n",
    "                print(cost)\n",
    "            st.subheader('--ìš”ì•½ê²°ê³¼--')\n",
    "            st.write(response)\n",
    "\n",
    "# íŒŒì´ì¬ íŒŒì¼ì´ ì‚¬ìš©ìì— ì˜í•´ ì§ì ‘ ì‹¤í–‰ë˜ë©´ main() í•¨ìˆ˜ë¥¼ ì‹¤í–‰í•˜ë¼\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d066b8-9d9c-47cc-a581-07bade2e631e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716faa8b-ba6b-4f4e-a989-2e2a9199bd97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_project",
   "language": "python",
   "name": "llm_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
