{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf187c22-110b-4463-98bf-b33e1195a962",
   "metadata": {},
   "source": [
    "## 프롬프트 생성\n",
    "- PromptTemplate : LLM 에 문장을 전달하기 전에 문장 구성을 편리하게 만들어주는 역할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86849aca-8d7b-4797-b2ba-8b0210e45f24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'카메라를 홍보하기 위한 좋은 문구를 추천해줘'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import PromptTemplate\n",
    "template = \"{product}를 홍보하기 위한 좋은 문구를 추천해줘\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables = [\"product\"],\n",
    "    template = template\n",
    ")\n",
    "\n",
    "prompt.format(product ='카메라')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98e6266-947a-4aca-aa5d-537e1e387138",
   "metadata": {},
   "source": [
    "## OpenAI 모델 LLM 호출\n",
    "- https://platform.openai.com/docs/models/gpt-4-and-gpt-4-tudo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "262b4212-cd08-4e77-9f1e-dfd25221a8d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install --upgrade langchain langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69c8715f-7bfb-4585-bff2-d2d23775a82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e0935bb6-0974-4d1c-bbee-67e9269b15ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "강아지입니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "llm1 = ChatOpenAI(\n",
    "    temperature= 0, # 창의성 0 으로 설정\n",
    "    model_name = 'gpt-4' # 모델명 () \n",
    ")\n",
    "\n",
    "prompt = \"진희는 강아지를 키우고 있습니다. 진희가 키우고 있는 동물은?\"\n",
    "print(llm1.predict(prompt))\n",
    "# print(llm1.invoke(prompt).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bde019f5-1823-4ad4-ab7f-eaeed2eb2e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c087c61e-5ed8-4cc0-bad2-e9d1d339f17e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "출력값: I'm not sure.\n"
     ]
    }
   ],
   "source": [
    "from langchain import HuggingFaceHub\n",
    "# llm2 = HuggingFaceHub(repo_id = \"google/flan-t5-xxl\", model_kwargs = {\"temperature\": 0.8, \"max_length\": 512})\n",
    "llm2 = HuggingFaceHub(repo_id = \"google/flan-t5-base\", model_kwargs = {\"temperature\": 0.8, \"max_length\": 512})\n",
    "\n",
    "# google/flan-t5-xxl : 큰 모델\n",
    "# google/flan-t5-large, flan-t5-base: 상대적으로 작은 모델 (성능이 떨어짐)\n",
    "\n",
    "promt = \"진희는 강아지를 키우고 있습니다. 진희가 키우고 있는 동물은?\"\n",
    "completion = llm2(promt)\n",
    "print(\"출력값:\", completion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625e59fb-2094-43ae-a499-9454798f5c9f",
   "metadata": {},
   "source": [
    "## 모델 성능 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60efd6dd-3d1a-4866-9358-c925390b9258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.model_laboratory import ModelLaboratory\n",
    "# model_lab = ModelLaboratory.from_llms([llm1, llm2])\n",
    "# model_lab.compare(\"대한민국의 가을은 몇 월부터 몇 월까지야?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03998fcd-7f39-4896-8444-7f13cd662224",
   "metadata": {},
   "source": [
    "## 출력파서\n",
    "- PydantcOutputParer: 입력된 데이터를 정의된 필드 타입에 맞게 자동으로 반환\n",
    "- SimpleJsonOutputParser: Json 형태로 결과를 반환\n",
    "- CommaSeparatedListOutputParer: 콤마(,)로 구분하여 결과를 반환합니다.\n",
    "- DatetimeOutputParser: 날짜/시간 형태로 결과를 반환 (예시. 1969-07-20 20:17:40)\n",
    "- XMLOutputParer: XML 형태로 결과를 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dd2787db-f4c6-4e22-b0e7-ec4e9e0000f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CommaSeparatedListOutputParer 작성 예제 확인\n",
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "# OpenAI의 GPT-4 모델을 초기화 (temperature 0으로 설정하여 출력 결과의 일관성을 높임)\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0,  # 창의성 0으로 설정 (예측에 있어 가장 일관된 답변을 기대)\n",
    "    max_tokens=2048,  # 최대 토큰 수 설정 (한 번의 예측에서 사용할 최대 토큰 수)\n",
    "    model_name='gpt-4'  # 사용할 모델 지정 (GPT-4 사용)\n",
    ")\n",
    "\n",
    "# 결과값을 콤마로 구분된 리스트로 변환해주는 출력 파서 초기화\n",
    "output_parser = CommaSeparatedListOutputParser()\n",
    "\n",
    "# 템플릿에 질의를 적용하여 완성된 문장을 LLM에 전달 (질의를 통해 결과 생성)\n",
    "output = llm.predict(text=prompt.format(subject=query))\n",
    "\n",
    "# PromptTemplate 생성\n",
    "# - 'subject' 변수는 사용자가 입력할 질의(query)에 해당\n",
    "# - 'format_instructions'는 파서가 요구하는 출력 형식을 반영\n",
    "prompt = PromptTemplate(\n",
    "    template=\"7개의 팀을 보여줘 {subject}. \\n {format_instructions}\",  # 템플릿 문장 (사용자 질의와 형식 요구 사항 포함)\n",
    "    input_variables=[\"subject\"],  # 사용자 입력을 받을 변수 (여기서는 'subject')\n",
    "    partial_variables={\"format_instructions\": format_instructions}  # 출력 형식 지정 (파서에서 전달된 형식 요구 사항)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8d6cee4e-5d96-4144-b660-33c96084e4b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['서울', '부산', '인천', '대구', '대전', '광주', '울산']\n"
     ]
    }
   ],
   "source": [
    "query = \"한국의 도시 이름은?\"\n",
    "\n",
    "# 출력 결과 생성\n",
    "output = llm.predict(text= prompt.format(subject = query))\n",
    "\n",
    "# 출력에 대한 포맷 변경\n",
    "parsed_result = output_parser.parse(output)\n",
    "print(parsed_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_project",
   "language": "python",
   "name": "llm_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
